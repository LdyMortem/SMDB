{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e2ec0b7",
   "metadata": {},
   "source": [
    "# Exercise 14 Balloon  Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2dfc6c3",
   "metadata": {},
   "source": [
    "#### In an experiment to measure the flux of cosmic rays in the upper atmosphere, protons with an energy between 1 GeV and 100 GeV are counted over a period of one hour from a flying balloon. Over a period of one week, a measurement run of one hour duration is made every day. The measured data are:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9642fc9",
   "metadata": {},
   "source": [
    "#### a) Assume that the cosmic ray flux is constant over the measurement period. Calculate the most probable count rate using the maximum likelihood method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1dc366",
   "metadata": {},
   "source": [
    "We can use a possion-distribution to describe our measurement since this is a counting experiment.\n",
    "So we get our likelihood function $L(\\lambda,i) = \\prod\\limits_{i}\\left( \\frac{\\lambda^{x_i}}{x_i!}e^{-\\lambda} \\right)$\n",
    "We have a $\\lambda =$ const ,since the counting rate is constant and $\\lambda$ describes exactly that.\n",
    "To get the most propable count rate we minimize the negativ log likelihood function for $\\lambda$.\n",
    "$\\frac{\\partial}{\\partial \\lambda} (-1)\\left( \\ln\\left( \\prod\\limits_{i}\\left( \\frac{\\lambda^{x_i}}{x_i!}e^{-\\lambda} \\right) \\right) \\right) = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d834da94",
   "metadata": {},
   "source": [
    "$\\leftrightarrow \\frac{\\partial}{\\partial \\lambda} (-1)\\left( \\sum\\limits_{i} \\ln\\left( \\frac{\\lambda^{x_i}}{x_i!}e^{-\\lambda} \\right) \\right) = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6284b234",
   "metadata": {},
   "source": [
    "$\\leftrightarrow \\frac{\\partial}{\\partial \\lambda} (-1)\\left( \\sum\\limits_{i} \\left( x_i\\ln(\\lambda) - \\ln(x_i!)-\\lambda\\right)\\right) = 0$ \n",
    "\n",
    "\n",
    "\n",
    "$\\leftrightarrow (-1)\\sum\\limits_{i} \\left(\\frac{x_i}{\\lambda}-1\\right) = (-1)\\frac{1}{\\lambda}\\left( \\sum\\limits_{i} x_i\\right)+N$ = 0\n",
    "\n",
    "\n",
    "$\\leftrightarrow \\lambda = \\frac{1}{N}\\sum\\limits_{i} x_i$\n",
    "\n",
    "This is the most popable count rate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78523265",
   "metadata": {},
   "source": [
    "#### b) Your colleague looks at the readings and hypothesizes that the cosmic ray flux is experiencing a dramatic increase. Assume a linearly increasing flux and calculate numerically the most probable flux parameters using the maximum likelihood method."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c93cd9c",
   "metadata": {},
   "source": [
    "Now we assume $\\lambda$ has a linear increase. So we have $\\lambda_i = a\\times i + \\lambda_0$\n",
    "With this we write down the negativ log-likelihood function as:\n",
    "$F = -\\ln(L) = -\\ln \\left( \\prod\\limits_{i}\\left( \\frac{(ai+\\lambda_0)^{x_i}}{x_i!}e^{-ai-\\lambda_0} \\right) \\right) = \\sum\\limits_{i} \\left(-x_i\\ln(ai+\\lambda_0) + \\ln(x_i!)+ ai+\\lambda_0\\right)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "08a3281e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The optimal Parameters are:\n",
      "a = 20.57199186555189\n",
      "lambda_0 = 4137.118883371033\n",
      "Most propable lambda_a = 4218.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize as op\n",
    "\n",
    "#numerical calculation of the most propable flux parameters\n",
    "ii = np.array([1,2,3,4,5,6,7])\n",
    "x_i = np.array([4135,4202,4203,4218,4227,4231,4310])\n",
    "def linearlambda(i,params):\n",
    "    return params[0]*i+params[1]\n",
    "def F_i(x,i,params):\n",
    "    return -x*np.log(linearlambda(i,params))+linearlambda(i,params)\n",
    "def F(params):\n",
    "    return F_i(x_i[0],ii[0],params)+F_i(x_i[1],ii[1],params)+F_i(x_i[2],ii[2],params)+F_i(x_i[3],ii[3],params)+F_i(x_i[4],ii[4],params)+F_i(x_i[5],ii[5],params)+F_i(x_i[6],ii[6],params)\n",
    "def lambda_a(x):\n",
    "    return np.mean(x)\n",
    "def F_i_new(count,params):\n",
    "    return F_i(x_new[count],ii_new[count],params)\n",
    "def F_new(params):\n",
    "    return F_i_new(1,params)+F_i_new(2,params)+F_i_new(3,params)+F_i_new(4,params)+F_i_new(5,params)+F_i_new(6,params)+F_i_new(7,params)\n",
    "\n",
    "parameters = op.minimize(F,[x_i[2]-x_i[1],x_i[1]], bounds=[(0,None),(0,None)])\n",
    "print(\"The optimal Parameters are:\")\n",
    "print(\"a =\",parameters.x[0])\n",
    "print(\"lambda_0 =\",parameters.x[1])\n",
    "\n",
    "\n",
    "#calculation of the most probable lambda in a) for c)\n",
    "print(\"Most propable lambda_a =\",lambda_a(x_i))\n",
    "lambda_av = lambda_a(x_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547df203",
   "metadata": {},
   "source": [
    "#### c) Calculate the significance of his observation using a likelihood ratio test. Evaluate the significance achieved. Hint: Assume that Wilks‚Äô theorem is valid here. Why can you assume this?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d580ba9",
   "metadata": {},
   "source": [
    "With the two likelihood functions from before we can calculate the ratio $\\Gamma$.\n",
    "$\\Gamma(i) = \\frac{\\prod\\limits_{i}\\left( \\frac{(ai+\\lambda_0)^{x_i}}{x_i!}e^{-ai-\\lambda_0}\\right)}{\\prod\\limits_{i}\\left( \\frac{\\lambda^{x_i}}{x_i!}e^{-\\lambda}\\right)} = \\prod\\limits_{i}\\left( \\left( \\frac{ai+\\lambda_0}{\\lambda} \\right)^{x_i}e^{\\lambda-ai-\\lambda_0} \\right)$\n",
    "With Wilks Theorem we get:\n",
    "$-2\\ln(\\Gamma) = \\sum\\limits_{i} \\left(-2\\left( x_i\\ln(\\frac{ai+\\lambda_0}{\\lambda}) +\\lambda - ai -\\lambda_0\\right)\\right)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0ee48969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Wilks-Ratio(or whatever) is given by Gamma_W = 3.106839501484501\n",
      "the Ratio is given by Gamma= 499.53566801117654\n"
     ]
    }
   ],
   "source": [
    "#using the calculated parameters from before:\n",
    "params_1 = np.array([lambda_av,parameters.x[0],parameters.x[1]])\n",
    "def ratio_wilks_i(x,i,params_r):\n",
    "    return -2*(x*np.log((params_r[1]*i+params_r[2])/params_r[0])+params_r[0]-params_r[1]*i-params_r[2])\n",
    "ratio = 0\n",
    "for i in range(len(ii)):\n",
    "    ratio = ratio + ratio_wilks_i(x_i[i],ii[i],params_1)\n",
    "print(\"The Wilks-Ratio(or whatever) is given by Gamma_W =\",-ratio)\n",
    "print(\"the Ratio is given by Gamma=\",np.exp(-2*ratio))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dd6d06",
   "metadata": {},
   "source": [
    "It is valid to use Wilks Theorem, because the Nullhypothesis($\\lambda =$ linear) is a linear transfrmation of the alternative hypothesis($\\lambda =$const) and the sample size is big enough."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8a68f7",
   "metadata": {},
   "source": [
    "### d) Your colleague performs another measurement a week later to support his thesis. His measurement results in Day 14 Counts 4402 Calculate (a) to (c) again for this new data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a61fed2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most propable const lambda = 4241.0\n",
      "The new optimal Parameters are:\n",
      "a_new = 17.944413991478562\n",
      "lambda_0_new = 4150.536280945702\n",
      "The Wilks-Ratio(or whatever) is given by Gamma_W = 9.905151403138007\n",
      "the Ratio is given by Gamma= 401333297.6592493\n"
     ]
    }
   ],
   "source": [
    "#initialisation of the new dataset\n",
    "x_new = np.array([4135,4202,4203,4218,4227,4231,4310,4402])\n",
    "ii_new = np.array([1,2,3,4,5,6,7,14])\n",
    "\n",
    "lambda_a_new = lambda_a(x_new)\n",
    "parameters_new = op.minimize(F_new,[x_new[2]-x_new[1],x_new[1]], bounds=[(0,None),(0,None)])\n",
    "print(\"The most propable const lambda =\",lambda_a_new)\n",
    "print(\"The new optimal Parameters are:\")\n",
    "print(\"a_new =\",parameters_new.x[0])\n",
    "print(\"lambda_0_new =\",parameters_new.x[1])\n",
    "\n",
    "#ratio\n",
    "\n",
    "params_1_new = np.array([lambda_a_new,parameters_new.x[0],parameters_new.x[1]])\n",
    "ratio_new = 0\n",
    "for i in range(len(ii_new)):\n",
    "    ratio_new = ratio_new + ratio_wilks_i(x_new[i],ii_new[i],params_1_new)\n",
    "print(\"The Wilks-Ratio(or whatever) is given by Gamma_W =\",-ratio_new)\n",
    "print(\"the Ratio is given by Gamma=\",np.exp(-2*ratio_new))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027b4b61",
   "metadata": {},
   "source": [
    "#### e) What is the methodological problem with exercise d)‚Äôs approach? Why should you not publish these results, even if the significance is higher then some preset threshold (e.g. 3 or 5ùúé)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04fa43b9",
   "metadata": {},
   "source": [
    "The new added value has a big time gap between the measurement. So The new data set is not able to describe the phenomenon from day 7 to day 13."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f772e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
